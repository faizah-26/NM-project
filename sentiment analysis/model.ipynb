{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI Echo Your Smartest Conversational Partner\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\AI Echo Your Smartest Conversational Partner\\myenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report,roc_auc_score,confusion_matrix,roc_curve\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD PROCESSED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>username</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_length</th>\n",
       "      <th>platform</th>\n",
       "      <th>language</th>\n",
       "      <th>location</th>\n",
       "      <th>version</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-15</td>\n",
       "      <td>Impressive</td>\n",
       "      <td>Mother former community upon vote fact. Sure s...</td>\n",
       "      <td>2</td>\n",
       "      <td>ybass</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>es</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>{'sentences': ['Mother former community upon v...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>Waste of Time</td>\n",
       "      <td>General paper understand main. Or age half won...</td>\n",
       "      <td>5</td>\n",
       "      <td>glenn33</td>\n",
       "      <td>71</td>\n",
       "      <td>193</td>\n",
       "      <td>Web</td>\n",
       "      <td>de</td>\n",
       "      <td>India</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'sentences': ['General paper understand main....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-16</td>\n",
       "      <td>Waste of Time</td>\n",
       "      <td>Here situation his high stage. Agree certainly...</td>\n",
       "      <td>4</td>\n",
       "      <td>debbie27</td>\n",
       "      <td>66</td>\n",
       "      <td>184</td>\n",
       "      <td>Web</td>\n",
       "      <td>hi</td>\n",
       "      <td>India</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'sentences': ['Here situation his high stage....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>Not Accurate</td>\n",
       "      <td>Rule court behind growth reality. Tonight whos...</td>\n",
       "      <td>1</td>\n",
       "      <td>hannahrussell</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>Web</td>\n",
       "      <td>fr</td>\n",
       "      <td>Canada</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'sentences': ['Rule court behind growth reali...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>Fantastic Experience</td>\n",
       "      <td>Case opportunity season road write. Effort gre...</td>\n",
       "      <td>3</td>\n",
       "      <td>cnorton</td>\n",
       "      <td>71</td>\n",
       "      <td>131</td>\n",
       "      <td>Web</td>\n",
       "      <td>hi</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4.1</td>\n",
       "      <td>No</td>\n",
       "      <td>{'sentences': ['Case opportunity season road w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                 title  \\\n",
       "0  2025-02-15            Impressive   \n",
       "1  2024-10-16         Waste of Time   \n",
       "2  2024-10-16         Waste of Time   \n",
       "3  2024-12-21          Not Accurate   \n",
       "4  2025-03-23  Fantastic Experience   \n",
       "\n",
       "                                              review  rating       username  \\\n",
       "0  Mother former community upon vote fact. Sure s...       2          ybass   \n",
       "1  General paper understand main. Or age half won...       5        glenn33   \n",
       "2  Here situation his high stage. Agree certainly...       4       debbie27   \n",
       "3  Rule court behind growth reality. Tonight whos...       1  hannahrussell   \n",
       "4  Case opportunity season road write. Effort gre...       3        cnorton   \n",
       "\n",
       "   helpful_votes  review_length platform language   location  version  \\\n",
       "0             68             78   Mobile       es     Canada      3.0   \n",
       "1             71            193      Web       de      India      4.1   \n",
       "2             66            184      Web       hi      India      4.1   \n",
       "3              5            193      Web       fr     Canada      4.0   \n",
       "4             71            131      Web       hi  Australia      4.1   \n",
       "\n",
       "  verified_purchase                                               text  \\\n",
       "0                No  {'sentences': ['Mother former community upon v...   \n",
       "1               Yes  {'sentences': ['General paper understand main....   \n",
       "2               Yes  {'sentences': ['Here situation his high stage....   \n",
       "3               Yes  {'sentences': ['Rule court behind growth reali...   \n",
       "4                No  {'sentences': ['Case opportunity season road w...   \n",
       "\n",
       "  sentiment  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Negative  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the string from the dictionary.\n",
    "df['lemmatized_words'] = df['text'].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\"))['lemmatized_words'])\n",
    "# Convert lists of words to strings\n",
    "df['lemmatized_sentences'] = df['lemmatized_words'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer pickle saved sucessfully\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['lemmatized_sentences'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train_vectors = vectorizer.fit_transform(x_train)\n",
    "x_test_vectors = vectorizer.transform(x_test)\n",
    "\n",
    "with open(\"tfidfvectorizer.pkl\",\"wb\") as file:\n",
    "    pickle.dump(vectorizer,file)\n",
    "\n",
    "print(\"vectorizer pickle saved sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentiment labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"sentiment_encoded\"] = label_encoder.fit_transform(df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVER SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(x_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAIN AND PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.82      0.75       450\n",
      "     Neutral       0.59      0.76      0.66       192\n",
      "    Positive       0.95      0.85      0.89      1358\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.74      0.81      0.77      2000\n",
      "weighted avg       0.85      0.83      0.84      2000\n",
      "\n",
      "[[ 370   29   51]\n",
      " [  35  145   12]\n",
      " [ 137   72 1149]]\n",
      "Roc_Auc score:0.9222166029923994\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-2, 1, 20)  # Alpha values from 0.01 to 10\n",
    "}\n",
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred= model.predict(x_test_vectors)\n",
    "y_pred_probability= model.predict_proba(x_test_vectors)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(f\"Roc_Auc score:{roc_auc_score(y_test,y_pred_probability,multi_class='ovr')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "\n",
    "# Create a dictionary with correct class labels\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train_resampled), class_weights)}\n",
    "\n",
    "model_svm = SVC(kernel='linear',C=1,probability=True,class_weight=class_weight_dict)\n",
    "model_svm.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_svm = model_svm.predict(x_test_vectors)\n",
    "y_pred_probability = model_svm.predict_proba(x_test_vectors)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test,y_pred_svm))\n",
    "\n",
    "print(f\"Roc_Auc score:{roc_auc_score(y_test,y_pred_probability,multi_class='ovr')}\")\n",
    "\n",
    "\n",
    "# --- 1. Confusion Matrix Heatmap ---\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# --- 2. ROC Curve for Multiclass (One-vs-Rest) ---\n",
    "# Binarize the output\n",
    "classes = np.unique(y_test)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "y_score = y_pred_probability\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(classes)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {classes[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"SVM ROC Curve - Multiclass\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.70      0.69       450\n",
      "     Neutral       0.22      0.97      0.36       192\n",
      "    Positive       0.99      0.51      0.67      1358\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.63      0.73      0.57      2000\n",
      "weighted avg       0.84      0.60      0.64      2000\n",
      "\n",
      "[[317 123  10]\n",
      " [  6 186   0]\n",
      " [149 520 689]]\n",
      "Roc_Auc Score :0.906452666930607\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "model_rf = RandomForestClassifier(max_depth=2)\n",
    "model_rf.fit(x_train_resampled,y_train_resampled)\n",
    "\n",
    "y_pred_rf = model_rf.predict(x_test_vectors)\n",
    "y_pred_proba = model_rf.predict_proba(x_test_vectors)\n",
    "print(accuracy_score(y_test,y_pred_rf))\n",
    "print(classification_report(y_test,y_pred_rf))\n",
    "print(confusion_matrix(y_test,y_pred_rf))\n",
    "print(f\"Roc_Auc Score :{roc_auc_score(y_test,y_pred_proba,multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LONG SHORT TERM MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 125ms/step - accuracy: 0.3275 - loss: 1.1021 - val_accuracy: 0.2250 - val_loss: 1.1269\n",
      "Epoch 2/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 113ms/step - accuracy: 0.3302 - loss: 1.0997 - val_accuracy: 0.0960 - val_loss: 1.1058\n",
      "Epoch 3/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 115ms/step - accuracy: 0.3327 - loss: 1.0996 - val_accuracy: 0.6790 - val_loss: 1.0815\n",
      "Epoch 4/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 153ms/step - accuracy: 0.3281 - loss: 1.0994 - val_accuracy: 0.0960 - val_loss: 1.1139\n",
      "Epoch 5/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 128ms/step - accuracy: 0.3331 - loss: 1.0993 - val_accuracy: 0.2250 - val_loss: 1.0978\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      1.00      0.37       450\n",
      "           1       0.00      0.00      0.00       192\n",
      "           2       0.00      0.00      0.00      1358\n",
      "\n",
      "    accuracy                           0.23      2000\n",
      "   macro avg       0.07      0.33      0.12      2000\n",
      "weighted avg       0.05      0.23      0.08      2000\n",
      "\n",
      "[[ 450    0    0]\n",
      " [ 192    0    0]\n",
      " [1358    0    0]]\n",
      "ROC AUC Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Define LSTM model\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=x_train_resampled.shape[1]),  # Word embedding\n",
    "    LSTM(128, return_sequences=True),  # First LSTM layer\n",
    "    LSTM(64),  # Second LSTM layer\n",
    "    Dropout(0.5),  # Dropout to prevent overfitting\n",
    "    Dense(3, activation='softmax')  # ✅ Output layer for 3-class classification\n",
    "])\n",
    "\n",
    "# Compile model ✅ Corrected loss function for multiclass\n",
    "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert sparse matrix to dense array before padding\n",
    "x_train_dense = x_train_resampled.toarray()\n",
    "x_test_dense = x_test_vectors.toarray()\n",
    "\n",
    "# Padding sequences\n",
    "x_train_padded = pad_sequences(x_train_dense, maxlen=100, padding='post', truncating='post')\n",
    "x_test_padded = pad_sequences(x_test_dense, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_resampled)  # Converts 'Positive', 'Negative', 'Neutral' to 0,1,2\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Ensure test labels follow the same mapping\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "y_train_resampled = np.array(y_train_encoded, dtype=np.int32)\n",
    "y_test = np.array(y_test_encoded, dtype=np.int32)\n",
    "\n",
    "# Convert labels to NumPy array ✅ Ensure correct data type\n",
    "y_train_resampled = np.array(y_train_resampled, dtype=np.int32)  # Labels should be integers: 0, 1, 2\n",
    "y_test = np.array(y_test, dtype=np.int32)\n",
    "\n",
    "# Train the model ✅ Use padded test data\n",
    "model_lstm.fit(x_train_padded, y_train_resampled, epochs=5, batch_size=16, validation_data=(x_test_padded, y_test))\n",
    "\n",
    "# Predictions\n",
    "y_pred_prob = model_lstm.predict(x_test_padded)  # Probabilities\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_prob, multi_class='ovr'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLE RNN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 54ms/step - accuracy: 0.3346 - loss: 1.1870 - val_accuracy: 0.0960 - val_loss: 1.2692\n",
      "Epoch 2/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43ms/step - accuracy: 0.3330 - loss: 1.1202 - val_accuracy: 0.0960 - val_loss: 1.1227\n",
      "Epoch 3/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - accuracy: 0.3381 - loss: 1.1043 - val_accuracy: 0.2250 - val_loss: 1.2004\n",
      "Epoch 4/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 46ms/step - accuracy: 0.3352 - loss: 1.1042 - val_accuracy: 0.6790 - val_loss: 1.0150\n",
      "Epoch 5/5\n",
      "\u001b[1m1003/1003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - accuracy: 0.3281 - loss: 1.1053 - val_accuracy: 0.0960 - val_loss: 1.1784\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       450\n",
      "           1       0.10      1.00      0.18       192\n",
      "           2       0.00      0.00      0.00      1358\n",
      "\n",
      "    accuracy                           0.10      2000\n",
      "   macro avg       0.03      0.33      0.06      2000\n",
      "weighted avg       0.01      0.10      0.02      2000\n",
      "\n",
      "[[   0  450    0]\n",
      " [   0  192    0]\n",
      " [   0 1358    0]]\n",
      "ROC AUC Score: 0.4979040092345089\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Define LSTM model\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=x_train_resampled.shape[1]),  # Word embedding\n",
    "    SimpleRNN(128, return_sequences=True),  # First LSTM layer\n",
    "    SimpleRNN(64),  # Second LSTM layer\n",
    "    Dropout(0.5),  # Dropout to prevent overfitting\n",
    "    Dense(3, activation='softmax')  # ✅ Output layer for 3-class classification\n",
    "])\n",
    "\n",
    "# Compile model ✅ Corrected loss function for multiclass\n",
    "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Convert sparse matrix to dense array before padding\n",
    "x_train_dense = x_train_resampled.toarray()\n",
    "x_test_dense = x_test_vectors.toarray()\n",
    "\n",
    "# Padding sequences\n",
    "x_train_padded = pad_sequences(x_train_dense, maxlen=100, padding='post', truncating='post')\n",
    "x_test_padded = pad_sequences(x_test_dense, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_resampled)  # Converts 'Positive', 'Negative', 'Neutral' to 0,1,2\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Ensure test labels follow the same mapping\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "y_train_resampled = np.array(y_train_encoded, dtype=np.int32)\n",
    "y_test = np.array(y_test_encoded, dtype=np.int32)\n",
    "\n",
    "# Convert labels to NumPy array ✅ Ensure correct data type\n",
    "y_train_resampled = np.array(y_train_resampled, dtype=np.int32)  # Labels should be integers: 0, 1, 2\n",
    "y_test = np.array(y_test, dtype=np.int32)\n",
    "\n",
    "# Train the model ✅ Use padded test data\n",
    "model_lstm.fit(x_train_padded, y_train_resampled, epochs=5, batch_size=16, validation_data=(x_test_padded, y_test))\n",
    "\n",
    "# Predictions\n",
    "y_pred_prob = model_lstm.predict(x_test_padded)  # Probabilities\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_prob, multi_class='ovr'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE PICKLE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"best_sentimental_model.pkl\",\"wb\") as file:\n",
    "    pickle.dump(model_svm,file)\n",
    "\n",
    "print(\"pickle file saved Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE VECTORISER AS PICKLE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"tf_idf_vectoriser.pkl\",\"wb\") as file:\n",
    "    pickle.dump(vectorizer,file)\n",
    "print(\"pickle file saved Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
